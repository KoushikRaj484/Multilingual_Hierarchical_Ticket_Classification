{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install nltk gensim"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2P-rfzQueFF",
        "outputId": "2c2f3790-0148-474b-b59c-7e803a51fcd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwR74ik6uQpc",
        "outputId": "c2b0dc2c-dd2a-4fa0-a1fb-cfb3102a2c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# STAGE 0: IMPORTS & DATA LOADING\n",
        "# =========================\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Embedding, Dense, Add, LayerNormalization,\n",
        "    MultiHeadAttention, Concatenate, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stop_english = set(stopwords.words(\"english\"))\n",
        "\n",
        "df = pd.read_csv(\"/content/aa_dataset-tickets-multi-lang-5-2-50-version.csv\")\n",
        "df.drop(\"tag_8\", axis=1, inplace=True)\n",
        "df = df[df[\"language\"] == \"en\"]\n",
        "\n",
        "df[[\"tag_1\",\"tag_2\",\"tag_3\",\"tag_4\",\"tag_5\",\"tag_6\",\"tag_7\"]] = \\\n",
        "df[[\"tag_1\",\"tag_2\",\"tag_3\",\"tag_4\",\"tag_5\",\"tag_6\",\"tag_7\"]].fillna(\"UNKNOWN\")\n",
        "\n",
        "df[\"text\"] = df[\"subject\"].fillna(\"\") + \" \" + df[\"body\"].fillna(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STAGE 1: TEXT CLEANING\n",
        "# =========================\n",
        "def clean_text(t):\n",
        "    if pd.isna(t):\n",
        "        return \"\"\n",
        "    t = t.lower()\n",
        "    tokens = word_tokenize(t)\n",
        "    tokens = [w for w in tokens if w not in stop_english and len(w) > 2]\n",
        "    t = \" \".join(tokens)\n",
        "    t = re.sub(r\"<.*?>\", \" \", t)\n",
        "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
        "    t = re.sub(r\"\\S+@\\S+\", \" \", t)\n",
        "    t = re.sub(r\"[^a-z\\s]\", \" \", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "U6dDXejVuULa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STAGE 2: LABEL ENCODING\n",
        "# =========================\n",
        "le_type = LabelEncoder()\n",
        "le_queue = LabelEncoder()\n",
        "\n",
        "df[\"type_encoded\"] = le_type.fit_transform(df[\"type\"])\n",
        "df[\"queue_encoded\"] = le_queue.fit_transform(df[\"queue\"])\n",
        "\n",
        "y_type = to_categorical(df[\"type_encoded\"].values)\n",
        "y_queue = to_categorical(df[\"queue_encoded\"].values)\n",
        "\n",
        "tags_cols = [\"tag_1\",\"tag_2\",\"tag_3\",\"tag_4\",\"tag_5\",\"tag_6\",\"tag_7\"]\n",
        "\n",
        "def clean_tags(row):\n",
        "    return [str(t) for t in row if str(t).lower() != \"unknown\"]\n",
        "\n",
        "df[\"tags_combined\"] = df[tags_cols].apply(clean_tags, axis=1)\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_tags = mlb.fit_transform(df[\"tags_combined\"])\n"
      ],
      "metadata": {
        "id": "V6xaSi32uWN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STAGE 3: TOKENIZATION\n",
        "# =========================\n",
        "MAX_NUM_WORDS = 20000\n",
        "MAX_SEQ_LEN = 200\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df[\"cleaned_text\"])\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(df[\"cleaned_text\"])\n",
        "X = pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding=\"pre\", truncating=\"pre\")\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n"
      ],
      "metadata": {
        "id": "FVs6gQO6uXMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STAGE 4: WORD2VEC EMBEDDINGS\n",
        "# =========================\n",
        "sentences = [t.split() for t in df[\"cleaned_text\"]]\n",
        "\n",
        "w2v_model = Word2Vec(\n",
        "    sentences,\n",
        "    vector_size=EMBEDDING_DIM,\n",
        "    window=5,\n",
        "    min_count=2,\n",
        "    workers=4\n",
        ")\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, idx in word_index.items():\n",
        "    if idx < num_words and word in w2v_model.wv:\n",
        "        embedding_matrix[idx] = w2v_model.wv[word]\n"
      ],
      "metadata": {
        "id": "cTIxT-XhuXJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STAGE 5: TRAIN / TEST SPLIT\n",
        "# =========================\n",
        "X_train, X_test, y_type_train, y_type_test, y_queue_train, y_queue_test, y_tags_train, y_tags_test = train_test_split(\n",
        "    X, y_type, y_queue, y_tags, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "99KeE4gau_Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STAGE 6: POSITIONAL ENCODING\n",
        "# =========================\n",
        "def positional_encoding(length, depth):\n",
        "    depth = depth // 2\n",
        "    positions = np.arange(length)[:, None]\n",
        "    depths = np.arange(depth)[None, :] / depth\n",
        "    angle_rates = 1 / (10000 ** depths)\n",
        "    angle_rads = positions * angle_rates\n",
        "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
        "    return tf.cast(pos_encoding[None, ...], tf.float32)\n",
        "\n",
        "pos_enc = positional_encoding(MAX_SEQ_LEN, EMBEDDING_DIM)\n"
      ],
      "metadata": {
        "id": "tkVLKzzyvCG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STAGE 7: TRANSFORMER ENCODER\n",
        "# =========================\n",
        "ENC_LAYERS = 2\n",
        "NUM_HEADS = 4\n",
        "FF_DIM = 512\n",
        "\n",
        "input_seq = Input(shape=(MAX_SEQ_LEN,), name=\"input_seq\")\n",
        "\n",
        "x = Embedding(\n",
        "    input_dim=num_words,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=False\n",
        ")(input_seq)\n",
        "\n",
        "x = Add()([x, pos_enc])\n",
        "\n",
        "for _ in range(ENC_LAYERS):\n",
        "    attn = MultiHeadAttention(\n",
        "        num_heads=NUM_HEADS,\n",
        "        key_dim=EMBEDDING_DIM // NUM_HEADS\n",
        "    )(x, x)\n",
        "    x = LayerNormalization()(Add()([x, attn]))\n",
        "\n",
        "    ff = Dense(FF_DIM, activation=\"relu\")(x)\n",
        "    ff = Dense(EMBEDDING_DIM)(ff)\n",
        "    x = LayerNormalization()(Add()([x, ff]))\n",
        "\n",
        "encoder_out = x   # (batch, seq_len, embed_dim)\n",
        "\n",
        "encoder_out = GlobalAveragePooling1D(name=\"encoder_pooling\")(encoder_out)\n",
        "\n",
        "# =========================\n",
        "# STAGE 8: MULTI-TASK OUTPUT HEADS\n",
        "# =========================\n",
        "type_branch = Dense(256, activation=\"relu\")(encoder_out)\n",
        "type_out = Dense(y_type.shape[1], activation=\"softmax\", name=\"type_out\")(type_branch)\n",
        "\n",
        "queue_input = Concatenate()([encoder_out, type_out])\n",
        "queue_branch = Dense(256, activation=\"relu\")(queue_input)\n",
        "queue_out = Dense(y_queue.shape[1], activation=\"softmax\", name=\"queue_out\")(queue_branch)\n",
        "\n",
        "tags_input = Concatenate()([encoder_out, queue_out])\n",
        "tags_branch = Dense(256, activation=\"relu\")(tags_input)\n",
        "tags_out = Dense(y_tags.shape[1], activation=\"sigmoid\", name=\"tags_out\")(tags_branch)\n",
        "\n",
        "# =========================\n",
        "# STAGE 9: BUILD & TRAIN\n",
        "# =========================\n",
        "model = Model(\n",
        "    inputs=input_seq,\n",
        "    outputs=[type_out, queue_out, tags_out]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "yUCLNj8xvEJH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64e5569c-a240-4a5b-ba04-3daab2f86dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_seq           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)  │  \u001b[38;5;34m1,497,000\u001b[0m │ input_seq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_46 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │    \u001b[38;5;34m361,200\u001b[0m │ add_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_47 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ add_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │        \u001b[38;5;34m600\u001b[0m │ add_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m512\u001b[0m)     │    \u001b[38;5;34m154,112\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │    \u001b[38;5;34m153,900\u001b[0m │ dense_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_48 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │        \u001b[38;5;34m600\u001b[0m │ add_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │    \u001b[38;5;34m361,200\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_49 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │        \u001b[38;5;34m600\u001b[0m │ add_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m512\u001b[0m)     │    \u001b[38;5;34m154,112\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │    \u001b[38;5;34m153,900\u001b[0m │ dense_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_50 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m300\u001b[0m)     │        \u001b[38;5;34m600\u001b[0m │ add_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_pooling     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │     \u001b[38;5;34m77,056\u001b[0m │ encoder_pooling[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ type_out (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │      \u001b[38;5;34m1,028\u001b[0m │ dense_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m304\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │ encoder_pooling[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ type_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │     \u001b[38;5;34m78,080\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ queue_out (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)           │      \u001b[38;5;34m2,570\u001b[0m │ dense_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m310\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │ encoder_pooling[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ queue_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │     \u001b[38;5;34m79,616\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ tags_out (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m862\u001b[0m)          │    \u001b[38;5;34m221,534\u001b[0m │ dense_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_seq           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,497,000</span> │ input_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">361,200</span> │ add_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ add_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">154,112</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,900</span> │ dense_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ add_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">361,200</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ add_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">154,112</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">153,900</span> │ dense_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│                     │                   │            │ dense_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ add_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_pooling     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">77,056</span> │ encoder_pooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ type_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │ dense_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_12      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">304</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_pooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ type_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">78,080</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ queue_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │ dense_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_13      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">310</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_pooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ queue_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">79,616</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ tags_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">862</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">221,534</span> │ dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,297,708\u001b[0m (12.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,297,708</span> (12.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,800,708\u001b[0m (6.87 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,800,708</span> (6.87 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,497,000\u001b[0m (5.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,497,000</span> (5.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer= 'adam',#tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss={\n",
        "        'type_out': 'categorical_crossentropy',\n",
        "        'queue_out': 'categorical_crossentropy',\n",
        "        'tags_out': 'binary_crossentropy'\n",
        "    },\n",
        "  # loss_weights={'type_out': 1.0, 'queue_out': 1.0, 'tags_out': 1.0},\n",
        "\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    {\n",
        "        \"type_out\": y_type_train,\n",
        "        \"queue_out\": y_queue_train,\n",
        "        \"tags_out\": y_tags_train\n",
        "    },\n",
        "    validation_split=0.1,\n",
        "    epochs=2,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXGXUkdZvJg_",
        "outputId": "97c6ca46-7388-41d2-ffe9-e48789447372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 59ms/step - loss: 2.2542 - queue_out_loss: 1.7655 - tags_out_loss: 0.0129 - type_out_loss: 0.4758 - val_loss: 2.2199 - val_queue_out_loss: 1.7565 - val_tags_out_loss: 0.0129 - val_type_out_loss: 0.4514\n",
            "Epoch 2/2\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 2.2021 - queue_out_loss: 1.7471 - tags_out_loss: 0.0127 - type_out_loss: 0.4424 - val_loss: 2.2088 - val_queue_out_loss: 1.7392 - val_tags_out_loss: 0.0132 - val_type_out_loss: 0.4572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics=  {\n",
        "        'type_out': ['accuracy'],\n",
        "        'queue_out': ['accuracy'],\n",
        "        'tags_out': ['accuracy']# [tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
        "    }"
      ],
      "metadata": {
        "id": "0UkakjfCvQ_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.models.save_model(model,'/content/model_ticket.keras')"
      ],
      "metadata": {
        "id": "mNCvP3k87iup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mO2l4XUF7ihj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/tokenizer_ticket.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "with open(\"/content/le_type.pkl\", \"wb\") as f:\n",
        "    pickle.dump(le_type, f)\n",
        "\n",
        "with open(\"/content/le_queue.pkl\", \"wb\") as f:\n",
        "    pickle.dump(le_queue, f)\n",
        "\n",
        "with open(\"/content/mlb.pkl\", \"wb\") as f:\n",
        "    pickle.dump(mlb, f)\n"
      ],
      "metadata": {
        "id": "2gRf9JMI-tvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.models.save_model(model,'/content/model_ticket1.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5xhDzRc-tpV",
        "outputId": "49ae36f6-c5a8-478f-ec1d-2c919d9495cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FtGmZmKt-tm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zqh9en85D8a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZJRHYvNRD8YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# STAGE 11: TEST / INFERENCE CODE\n",
        "# ===============================\n",
        "def preprocess_single_text(text):\n",
        "    text = clean_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    seq = pad_sequences(seq, maxlen=MAX_SEQ_LEN, padding=\"pre\", truncating=\"pre\")\n",
        "    return seq\n",
        "\n",
        "def predict_ticket(text):\n",
        "    X_in = preprocess_single_text(text)\n",
        "\n",
        "    type_p, queue_p, tags_p = model.predict(X_in)\n",
        "\n",
        "    type_label = le_type.inverse_transform([np.argmax(type_p)])[0]\n",
        "    queue_label = le_queue.inverse_transform([np.argmax(queue_p)])[0]\n",
        "\n",
        "    tag_indices = np.where(tags_p[0] > 0.5)[0]\n",
        "    tag_labels = mlb.classes_[tag_indices]\n",
        "\n",
        "    return {\n",
        "        \"predicted_type\": type_label,\n",
        "        \"predicted_queue\": queue_label,\n",
        "        \"predicted_tags\": list(tag_labels),\n",
        "        \"type_confidence\": float(np.max(type_p)),\n",
        "        \"queue_confidence\": float(np.max(queue_p))\n",
        "    }\n"
      ],
      "metadata": {
        "id": "nJ35DRjo-tiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# STAGE 12: SAMPLE TEST\n",
        "# =========================\n",
        "sample_text = \"\"\"\n",
        "Unable to access my account after password reset.\n",
        "The system throws authentication error.\n",
        "\"\"\"\n",
        "\n",
        "result = predict_ticket(sample_text)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKLo5XUc-tfd",
        "outputId": "948aeb36-917e-4d9f-ff43-3754c09f77a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "{'predicted_type': 'Incident', 'predicted_queue': 'Technical Support', 'predicted_tags': ['IT', 'Performance', 'Tech Support'], 'type_confidence': 0.6518449783325195, 'queue_confidence': 0.4231639802455902}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq081yBeFL5u",
        "outputId": "b116d01d-0d5e-44f2-a8e0-4c1472c65331"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Functional name=functional_6, built=True>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YtWvA3znFwq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}